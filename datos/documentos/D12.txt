La computacion paralela y distribuida aprovecha multiples procesadores para resolver problemas computacionalmente intensivos. Los sistemas multiprocesador comparten memoria entre nucleos para comunicacion rapida. Los clusters conectan computadores independientes mediante redes de alta velocidad. La computacion en la nube proporciona recursos virtualizados bajo demanda. Los algoritmos paralelos dividen tareas en subtareas ejecutables concurrentemente. La sincronizacion coordina acceso a recursos compartidos entre procesos paralelos. Los paradigmas de programacion paralela incluyen memoria compartida y paso de mensajes. OpenMP facilita paralelizacion en sistemas de memoria compartida mediante directivas. MPI estandariza comunicacion en sistemas distribuidos de memoria distribuida. Los patrones de paralelizacion como map-reduce simplifican desarrollo de aplicaciones escalables. La granularidad determina el tama√±o de tareas paralelas para optimizar rendimiento. El balanceamiento de carga distribuye trabajo uniformemente entre procesadores disponibles. Los modelos de consistencia definen semantica de acceso a memoria compartida. Las tecnicas de tolerancia a fallos mantienen funcionamiento ante fallas de componentes. La escalabilidad mide como el rendimiento cambia al aumentar recursos de computo. Los cuellos de botella limitan el rendimiento maximo alcanzable en sistemas paralelos. La ley de Amdahl cuantifica la mejora maxima esperable mediante paralelizacion. Los debuggers paralelos ayudan a detectar errores de concurrencia como deadlocks. Las herramientas de profiling identifican secciones de codigo que consumen mas tiempo. La optimizacion de comunicacion minimiza transferencias costosas entre procesadores.
